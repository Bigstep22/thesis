\section{Introduction}
When writing functional code, we often use functions (or other data structures) to `glue' multiple pieces of data together.
Take, as an example, the following function in the programming language Haskell, as introduced by \cite{Gill1993}: %TODO: Cite
\begin{code}
all :: (a -> Bool) -> [a] -> Bool
all p = and . map p
\end{code}
The function \tt{map p} traverses across the input list, applying the predicate \tt{p} to each element, resulting in a new boolean list.
Then, the function \tt{and} takes this resulting, intermediate, boolean list and consumes it by `and-ing' together all the boolean values.

Being able to compose functions in this fashion is part of what makes functional programming so attractive, but it comes at the cost of computational overhead:
Each time allocating a list cell, only to subsequently deallocate it once the value has been read.
We could instead rewrite \tt{all} in the following fashion:
\begin{code}
all' p xs = h xs
  where h []     = True
        h (x:xs) = p x && h xs
\end{code}
This function, instead of traversing the input list, producing a new list, and then subsequently traversing that intermediate list, traverses the input list only once; immediately producing a new answer.
Writing code in this fashion is far more performant, at the cost of read- and write-ability.
Can you write a high-performance, single-traversal, version of the following function \citep{Harper2011}?
\begin{code}
f :: (Int, Int) -> Int
f = sum . map (+1) . filter odd . between
\end{code}
With some (more) effort and optimization, one could arrive at the following solution:
\begin{code}
f' :: (Int, Int) -> Int
f' (x, y) = loop x
  where loop x | x > y    = 0
               |otherwise = if odd x
                             then (x+1) + loop (x+1)
                             else loop (x+1)
\end{code}
Doing this by hand every time, to get from the nice, elegant, compositional style of programming to the higher-performance, single-traversal style, gets old very quick.
Especially if this needs to be done, by hand, \textbf{every} time you compose any two functions.
Is there some way to automate this process?
\paragraph{Fusion}
The answer is yes*, but it comes with an asterisk attached, namely that the functions that we are working with are folds or unfolds.
The form of optimization that we are looking for is called fusion:
The process of taking multiple list producing/consuming functions and turning (or fusing) them into just one.

Much work already exists, which is discussed in detail in \autoref{sec:related}.
My thesis focuses on a specific form of fusion called shortcut fusion through the use of (Co)Church encodings as described by \cite{Harper2011} and asks the following two questions:
\begin{enumerate}
  \item To implement (Co)Church encodings, what is necessary to make the code reliably fuse? This leads to the following sub-questions:
  \begin{itemize}
    \item What transformations can be used within Haskell to enable fusion to work?
    \item What tools and techniques are available to get Haskell's compiler to cooperate and trigger fusion?
  \end{itemize}
  \item Are the transformations used to enable fusion safe? Meaning:
  \begin{itemize}
    \item Do the transformations in Haskell preserve the semantics of the languagage?
    \item If the mathematics and the encodings are implemented in a dependently typed langauge, can the transformation be proved to be correct?
  \end{itemize}
\end{enumerate}

My thesis centers on formalizing, replicating, and expanding upon \cite{Harper2011}'s work and makes two crucial contributions, answering the two questions above:
\begin{enumerate}
    \item The Church and Cochurch encodings' implementation in Haskell, as described by \cite{Harper2011} are replicated and investigated further as to their performance characteristics.
    In this process, a weakness was found in Haskell's optimizer, and further practical insights were gleaned as to how to get these encodings to properly fuse as well (especially for Cochurch encodings) and what optimizations enable shortcut fusion to do its work.

    This is important as \cite{Harper2011} gave a good pragmatic explanation as to how to implement the (Co)Church encodings in Haskell, gave an example implementation, and benchmarked that implementation.
    He did not dive into too much detail as to \textit{why} they work stating, ``Interestingly, however, we note that Cochurch encodings consistently outperform Church encodings, sometimes by a significant margin. While we do consider these results conclusive, we think that these results merit further investigation.'' \citep{Harper2011}.
    This is what my research has (partially) set out to look into.
    This is discussed in detail in \autoref{sec:haskell}.
    \item The Church and Cochurch encodings described are formalized and implemented, including the relevant category theory, in Agda, in as a general fashion as possible, leveraging containers \citep{Abbott2005} to represent strictly positive functors.
    Furthermore, the functions that are described (producing, transforming, and consuming) are also implemented in a general fashion and shown to be equal to regular folds (i.e., catamorphisms and anamorphisms).

    This is important because there currently does not seem to exist a formalization of the work.
    Formally verifying the mathematics will strengthen the work done by \cite{Harper2011}, perhaps also aiding in understanding in how the different pieces of mathematics relate.
    This is discussed in detail in \autoref{sec:formalization}.
\end{enumerate}




% Mention certain existing solutions, shortcut deforestation, library shortcut fusion, etc. DO RESEARCH

%% Focus down on the Church encodings and that they are rather general, but seemingly not formalized.
%%% Agda was used to formalize it, done in section X
%%%% Haskell implementation of the work was also done, work was continued to investigate why sometimes Co(Church) encodings are faster, done in section X.
%%%%% Mention that new discoveries were made throughout the Haskell implementation process.
~

% Fusion, Category theory, Libfusion paper, church encodings, formalization of it, Haskell's suite of optimizations that enable fusion, (theorems for free?).


